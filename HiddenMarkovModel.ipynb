{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.11"
    },
    "colab": {
      "name": "HiddenMarkovModel.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/apester/HiddenMarkovModel_TensorFlow/blob/master/HiddenMarkovModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56p8EtaRGScw",
        "colab_type": "text"
      },
      "source": [
        "# Hidden Markov Model in TensorFlow\n",
        "## Package Includes (so far):\n",
        "* **Viterbi Algorithm**\n",
        "    * Maximum a Posteri\n",
        "<br>\n",
        "<br>\n",
        "* **Forward-Backward Algorithm**\n",
        "    * Posterior Marginals\n",
        "<br>\n",
        "<br>\n",
        "* **Baum Welch Algorithm**\n",
        "    * Expectation Maximization Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdNWfKEWGScx",
        "colab_type": "text"
      },
      "source": [
        "## HMM Fundamentals\n",
        "\n",
        "**HMM recap:**\n",
        "* Undirected graphical model.\n",
        "* Connections between nodes indicate dependence.\n",
        "* We observe $Y_1$ through $Y_n$, which we model as being observed from hidden states $S_1$ through $S_n$.\n",
        "* Any particular state variable $S_k$ depends only on $S_{k−1}$ (what came before it), $S_{k+1}$ (what comes after it), and $Y_k$ (the observation associated with it).\n",
        "\n",
        "** HMM are specified by three sets of parameters**\n",
        "\n",
        "* ** Transition distribution:**\n",
        "    * describes the distribution for the next state given the current state.\n",
        "    * $P(next State| current State)$\n",
        "<br>\n",
        "<br>\n",
        "* ** Emission distribution:**\n",
        "    * describes the distribution for the output given the current state.\n",
        "    * $P(Observation|current State)$\n",
        "<br>\n",
        "<br>\n",
        "* ** Initial state distribution:**\n",
        "    * describes the starting distribution over states.\n",
        "    * $P(initial State)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9w-oVOhGScx",
        "colab_type": "text"
      },
      "source": [
        "![](https://github.com/apester/HiddenMarkovModel_TensorFlow/blob/master/images/hmm.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "radfGaUSGScy",
        "colab_type": "text"
      },
      "source": [
        "### State Transitions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkSI7y2YGScy",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://github.com/apester/HiddenMarkovModel_TensorFlow/blob/master/images/trans2.png?raw=1\" width=\"500\" height=\"500\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnjG_9sKGScy",
        "colab_type": "text"
      },
      "source": [
        "## Viterbi Algorithm\n",
        "* Efficient way of finding the most likely state sequence.\n",
        "* Method is general statistical framework of compound decision theory. \n",
        "* Maximizes a posteriori probability recursively.\n",
        "* Assumed to have a finite-state discrete-time Markov process.\n",
        "\n",
        "**Maximum a posteri (MAP) probability, given by:** <br>\n",
        "$$P(States|Observations) = \\dfrac{P(Observations)| States)P(States)}{P(Observations)}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_y6Byh_AGScz",
        "colab_type": "text"
      },
      "source": [
        "Given a hidden Markov model (HMM) with:\n",
        "* State space S\n",
        "* Initial probabilities $\\pi_i$ of being in state $i$\n",
        "* Transition probabilities $a_{i,j}$ of transitioning from state i to state j.\n",
        "* We observe outputs $y_1$,$\\dots$, $y_T$.\n",
        "* The most likely state sequence $x_1$,$\\dots$,$x_T$ that produces the observations is given by the recurrence relations:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTaZe3hjGScz",
        "colab_type": "text"
      },
      "source": [
        "$$ V_{1,k} = P(y_1 | k) \\cdot \\pi_k$$\n",
        "\n",
        "$$ V_{t,k} = max_x(P(y_t|k)\\cdot a_{x,k} \\cdot V_{t-1,x}$$\n",
        "\n",
        "* $V_{t,k}$ is the probability of the most probable state sequence $\\mathrm{P}\\big(x_1,\\dots,x_T,y_1,\\dots, y_T\\big)$\n",
        "* The Viterbi path can be retrieved by saving back pointers that remember which state x was used in the second equation.\n",
        "* Let $\\mathrm{Ptr}(k,t)$ be the function that returns the value of x used to compute $V_{t,k}$ if $t > 1$, or $k$ if $t=1$. Then:\n",
        "\n",
        "$$ x_T = argmax_x(V_{T,x})$$\n",
        "\n",
        "$$ x_{t-1} = Ptr(x_{t}, t)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChvHMLWkGSc0",
        "colab_type": "text"
      },
      "source": [
        "### Shortest Route Task\n",
        "The MAP sequence estimation problem previously stated can also be viewed as the problem of finding the shortest route through a certain graph.\n",
        "\n",
        "**Representing an HMM as a trellis**\n",
        "* Each node corresponds to a distinct state at a given time\n",
        "* Each arrow represents a transition to some new state at the next instant of time.\n",
        "* The trellis begins and ends at the known states c0 and cn.\n",
        "* Its most important property is that to every possible state sequence C there corresponds a unique path through the trellis, and vice versa."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGq3EmApGSc0",
        "colab_type": "text"
      },
      "source": [
        "![](https://github.com/apester/HiddenMarkovModel_TensorFlow/blob/master/images/graph1.gif?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DKLYQonGSc0",
        "colab_type": "text"
      },
      "source": [
        "* Assign to every path a length proportional to $-log [p(Observations)| States)+P(States)]$.\n",
        "* $log()$ is a monotonic function and there is a one-to-one correspondence between paths and sequences, we only need to find the path whose $-log [p(Observations)| States)+P(States)]$ is minimum.\n",
        "* This will give us the state sequence for which $p(Observations)| States) \\cdot P(States)$ is maximum.\n",
        "* This is the state sequence with the maximum a posteriori (MAP) probability.\n",
        "\n",
        "#### Graph Search\n",
        "Four-state trellis covering five time units."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1YzFWg1GSc1",
        "colab_type": "text"
      },
      "source": [
        "![](https://github.com/apester/HiddenMarkovModel_TensorFlow/blob/master/images/graph2.gif?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiTbETsOGSc1",
        "colab_type": "text"
      },
      "source": [
        "#### Recursive Steps\n",
        "The 5 recursive steps by which the algorithm determines the shortest path from the initial to the final node are shown in here. At each step only the 4 (or fewer) survivors are shown, along with their lengths."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMFB2QjtGSc2",
        "colab_type": "text"
      },
      "source": [
        "![](https://github.com/apester/HiddenMarkovModel_TensorFlow/blob/master/images/graph3.gif?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuGHoHJOGSc2",
        "colab_type": "text"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdENp1WdGSc2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "555abd9a-9147-40ca-8902-b866f4b64d41"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from __future__ import print_function\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sh-d7JtiGSc5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dptable(state_prob):\n",
        "    print(\" \".join((\"%8d\" % i) for i in range(state_prob.shape[0])))\n",
        "    for i, prob in enumerate(state_prob.T):\n",
        "        print(\"%.7s: \" % states[i] +\" \".join(\"%.7s\" % (\"%f\" % p) for p in prob))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BA4Gyk0WGSc8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def highlight_max(s):\n",
        "    '''\n",
        "    highlight the maximum in a Series yellow.\n",
        "    '''\n",
        "    is_max = s == s.max()\n",
        "    return ['background-color: yellow' if v else '' for v in is_max]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwHvsct-GSc-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from HiddenMarkovModel import HiddenMarkovModel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZSlLc2ZK5d6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "__author__ = 'MarvinBertin'\n",
        "\n",
        "\n",
        "class HiddenMarkovModel(object):\n",
        "\n",
        "    \"\"\"\n",
        "    Hidden Markov Model Class\n",
        "    Parameters:\n",
        "    -----------\n",
        "    \n",
        "    - S: Number of states.\n",
        "    - T: Transition matrix of size S by S\n",
        "         stores probability from state i to state j.\n",
        "    - E: Emission matrix of size S by N (number of observations)\n",
        "         stores the probability of observing  O_j  from state  S_i. \n",
        "    - T0: Initial state probabilities of size S.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, T, E, T0, epsilon = 0.001, maxStep = 10):\n",
        "        \n",
        "        with tf.name_scope('Inital_Parameters'):\n",
        "            with tf.name_scope('Scalar_constants'):\n",
        "                # Max number of iteration\n",
        "                self.maxStep = maxStep\n",
        "\n",
        "                # convergence criteria\n",
        "                self.epsilon = epsilon \n",
        "\n",
        "                # Number of possible states\n",
        "                self.S = T.shape[0]\n",
        "\n",
        "                # Number of possible observations\n",
        "                self.O = E.shape[0]\n",
        "                \n",
        "                self.prob_state_1 = []\n",
        "\n",
        "            with tf.name_scope('Model_Parameters'):\n",
        "                # Emission probability\n",
        "                self.E = tf.Variable(E, dtype=tf.float64, name='emission_matrix')\n",
        "\n",
        "                # Transition matrix\n",
        "                self.T = tf.Variable(T, dtype=tf.float64, name='transition_matrix')\n",
        "\n",
        "                # Initial state vector\n",
        "                self.T0 = tf.Variable(tf.constant(T0, dtype=tf.float64, name='inital_state_vector'))\n",
        "    \n",
        "\n",
        "    def initialize_viterbi_variables(self, shape):\n",
        "        \n",
        "        pathStates = tf.Variable(tf.zeros(shape, dtype=tf.int64), name='States_matrix')\n",
        "        pathScores = tf.Variable(tf.zeros(shape, dtype=tf.float64), name='Score_matrix')\n",
        "        states_seq = tf.Variable(tf.zeros([shape[0]], dtype=tf.int64), name='States_sequence')\n",
        "        return pathStates, pathScores, states_seq\n",
        "    \n",
        "    def belief_propagation(self, scores):\n",
        "        \n",
        "        scores_reshape = tf.reshape(scores, (-1,1))\n",
        "        return tf.add(scores_reshape, tf.log(self.T))\n",
        "    \n",
        "    def viterbi_inference(self, obs_seq):\n",
        "        \n",
        "        # length of observed sequence\n",
        "        self.N = len(obs_seq)\n",
        "        \n",
        "        # shape path Variables\n",
        "        shape = [self.N, self.S]\n",
        "        \n",
        "        # observed sequence\n",
        "        x = tf.constant(obs_seq, dtype=tf.int32, name='observation_sequence')\n",
        "        \n",
        "        with tf.name_scope('Init_viterbi_variables'):\n",
        "            # Initialize variables\n",
        "            pathStates, pathScores, states_seq = self.initialize_viterbi_variables(shape)       \n",
        "        \n",
        "        with tf.name_scope('Emission_seq_'):\n",
        "            # log probability of emission sequence\n",
        "            obs_prob_seq = tf.log(tf.gather(self.E, x))\n",
        "            obs_prob_list = tf.split(obs_prob_seq, self.N, 0)\n",
        "\n",
        "        with tf.name_scope('Starting_log-priors'):\n",
        "            # initialize with state starting log-priors\n",
        "            pathScores = tf.scatter_update(pathScores, 0, tf.log(self.T0) + tf.squeeze(obs_prob_list[0]))\n",
        "            \n",
        "        \n",
        "        with tf.name_scope('Belief_Propagation'):\n",
        "            for step, obs_prob in enumerate(obs_prob_list[1:]):\n",
        "\n",
        "                with tf.name_scope('Belief_Propagation_step_%s' %step):\n",
        "                    # propagate state belief\n",
        "                    belief = self.belief_propagation(pathScores[step, :])\n",
        "\n",
        "                    # the inferred state by maximizing global function\n",
        "                    # and update state and score matrices \n",
        "                    pathStates = tf.scatter_update(pathStates, step + 1, tf.argmax(belief, 0))\n",
        "                    pathScores = tf.scatter_update(pathScores, step + 1, tf.reduce_max(belief, 0) + tf.squeeze(obs_prob))\n",
        "\n",
        "            with tf.name_scope('Max_Likelyhood_update'):\n",
        "                # infer most likely last state\n",
        "                states_seq = tf.scatter_update(states_seq, self.N-1, tf.argmax(pathScores[self.N-1, :], 0))\n",
        "        \n",
        "        with tf.name_scope('Backtrack'):\n",
        "            for step in range(self.N - 1, 0, -1):\n",
        "                with tf.name_scope('Back_track_step_%s' %step):\n",
        "                    # for every timestep retrieve inferred state\n",
        "                    state = states_seq[step]\n",
        "                    idx = tf.reshape(tf.stack([step, state]), [1, -1])\n",
        "                    state_prob = tf.gather_nd(pathStates, idx)\n",
        "                    states_seq = tf.scatter_update(states_seq, step - 1,  state_prob[0])\n",
        "\n",
        "        return states_seq, tf.exp(pathScores) # turn scores back to probabilities\n",
        "    \n",
        "    def run_viterbi(self, obs_seq, summary=False):\n",
        "        \n",
        "        state_graph, state_prob_graph = self.viterbi_inference(obs_seq)\n",
        "        \n",
        "        with tf.Session() as sess:\n",
        "            \n",
        "            sess.run(tf.initialize_all_variables())\n",
        "            states_seq, state_prob = sess.run([state_graph, state_prob_graph])\n",
        "            \n",
        "            if summary:\n",
        "                # Instantiate a SummaryWriter to output summaries and the Graph.\n",
        "                summary_writer = tf.summary.FileWriter('logs/', graph=sess.graph)\n",
        "\n",
        "        return states_seq, state_prob\n",
        "    \n",
        "    def initialize_forw_back_variables(self, shape):\n",
        "        self.forward = tf.Variable(tf.zeros(shape, dtype=tf.float64), name='forward')\n",
        "        self.backward = tf.Variable(tf.zeros(shape, dtype=tf.float64), name='backward')\n",
        "        self.posterior = tf.Variable(tf.zeros(shape, dtype=tf.float64), name='posteriror')\n",
        "\n",
        "\n",
        "    def _forward(self, obs_prob_list):\n",
        "        \n",
        "        with tf.name_scope('init_scaling_factor'):\n",
        "            self.scale = tf.Variable(tf.zeros([self.N], tf.float64)) #scale factors\n",
        "        \n",
        "        with tf.name_scope('forward_first_step'):\n",
        "            # initialize with state starting priors\n",
        "            init_prob = tf.multiply(self.T0, tf.squeeze(obs_prob_list[0]))\n",
        "\n",
        "            # scaling factor at t=0\n",
        "            self.scale = tf.scatter_update(self.scale, 0, 1.0 / tf.reduce_sum(init_prob))\n",
        "\n",
        "            # scaled belief at t=0\n",
        "            self.forward = tf.scatter_update(self.forward, 0, self.scale[0] * init_prob)\n",
        "\n",
        "        # propagate belief\n",
        "        for step, obs_prob in enumerate(obs_prob_list[1:]):\n",
        "            with tf.name_scope('time_step-%s' %step):\n",
        "                # previous state probability\n",
        "                prev_prob = tf.expand_dims(self.forward[step, :], 0)\n",
        "                # transition prior\n",
        "                prior_prob = tf.matmul(prev_prob, self.T)\n",
        "                # forward belief propagation\n",
        "                forward_score = tf.multiply(prior_prob, tf.squeeze(obs_prob))\n",
        "\n",
        "                forward_prob = tf.squeeze(forward_score)\n",
        "                # scaling factor\n",
        "                self.scale = tf.scatter_update(self.scale, step+1, 1.0 / tf.reduce_sum(forward_prob))\n",
        "                # Update forward matrix\n",
        "                self.forward = tf.scatter_update(self.forward, step+1, self.scale[step+1] * forward_prob)\n",
        "        \n",
        "\n",
        "    def _backward(self, obs_prob_list):\n",
        "        with tf.name_scope('backward_last_step'):\n",
        "            # initialize with state ending priors\n",
        "            self.backward = tf.scatter_update(self.backward, 0, self.scale[self.N-1] * tf.ones([self.S], dtype=tf.float64)) \n",
        "\n",
        "        # propagate belief\n",
        "        for step, obs_prob in enumerate(obs_prob_list[:-1]):\n",
        "            with tf.name_scope('time_step-%s' %step):\n",
        "                # next state probability\n",
        "                next_prob = tf.expand_dims(self.backward[step, :], 1)\n",
        "                # observation emission probabilities\n",
        "                obs_prob_d = tf.diag(tf.squeeze(obs_prob))\n",
        "                # transition prior\n",
        "                prior_prob = tf.matmul(self.T, obs_prob_d)\n",
        "                # backward belief propagation\n",
        "                backward_score = tf.matmul(prior_prob, next_prob)\n",
        "\n",
        "                backward_prob = tf.squeeze(backward_score)\n",
        "\n",
        "                # Update backward matrix\n",
        "                self.backward = tf.scatter_update(self.backward, step+1, self.scale[self.N-2-step] * backward_prob)\n",
        "        \n",
        "        self.backward = tf.assign(self.backward, tf.reverse(self.backward, [True, False]))\n",
        "\n",
        "        \n",
        "    def _posterior(self):\n",
        "        # posterior score\n",
        "        self.posterior = tf.multiply(self.forward, self.backward)\n",
        "\n",
        "        marginal = tf.reduce_sum(self.posterior, 1)\n",
        "        self.posterior = self.posterior / tf.expand_dims(marginal, 1)       \n",
        "        \n",
        "        \n",
        "    def re_estimate_emission(self, x):\n",
        "        \n",
        "        states_marginal = tf.reduce_sum(self.gamma, 0)\n",
        "        seq_one_hot = tf.one_hot(tf.cast(x, tf.int64), self.O, 1, 0)\n",
        "        emission_score = tf.matmul(tf.cast(seq_one_hot, tf.float64), self.gamma, transpose_a=True)\n",
        "        return emission_score / states_marginal\n",
        "    \n",
        "    def re_estimate_transition(self, x):\n",
        "        \n",
        "        with tf.name_scope('Init_3D_tensor'):\n",
        "            self.M = tf.Variable(tf.zeros((self.N-1, self.S, self.S), tf.float64))\n",
        "        \n",
        "        with tf.name_scope('3D_tensor_transition'):\n",
        "            for t in range(self.N - 1):\n",
        "                with tf.name_scope('time_step-%s' %t):\n",
        "                    tmp_0 = tf.matmul(tf.expand_dims(self.forward[t, :], 0), self.T)\n",
        "                    tmp_1 = tf.multiply(tmp_0, tf.expand_dims(tf.gather(self.E, x[t+1]), 0))\n",
        "                    denom = tf.squeeze(tf.matmul(tmp_1, tf.expand_dims(self.backward[t+1, :], 1)))\n",
        "\n",
        "                with tf.name_scope('Init_new_transition'):\n",
        "                    trans_re_estimate = tf.Variable(tf.zeros((self.S, self.S), tf.float64))\n",
        "                    \n",
        "                for i in range(self.S):\n",
        "                    with tf.name_scope('State-%s' %i):\n",
        "                        numer = self.forward[t, i] * self.T[i, :] * tf.gather(self.E, x[t+1]) * self.backward[t+1, :]\n",
        "                        trans_re_estimate = tf.scatter_update(trans_re_estimate, i, numer / denom)\n",
        "\n",
        "                self.M = tf.scatter_update(self.M, t, trans_re_estimate)\n",
        "\n",
        "        with tf.name_scope('Smooth_gamma'):\n",
        "            self.gamma = tf.squeeze(tf.reduce_sum(self.M, 2))\n",
        "            T_new = tf.reduce_sum(self.M, 0) / tf.expand_dims(tf.reduce_sum(self.gamma, 0), 1)\n",
        "        \n",
        "        with tf.name_scope('New_init_states_prob'):\n",
        "            T0_new = self.gamma[0,:]\n",
        "\n",
        "        with tf.name_scope('Append_gamma_final_time_step'):\n",
        "            prod = tf.expand_dims(tf.multiply(self.forward[self.N-1, :], self.backward[self.N-1, :]), 0)\n",
        "            s= prod/ tf.reduce_sum(prod)\n",
        "            self.gamma = tf.concat([self.gamma, s], 0)\n",
        "            \n",
        "            self.prob_state_1.append(self.gamma[:, 0])\n",
        "        \n",
        "        return T0_new, T_new\n",
        "    \n",
        "    def check_convergence(self, new_T0, new_transition, new_emission):\n",
        "        \n",
        "        delta_T0 = tf.reduce_max(tf.abs(self.T0 - new_T0)) < self.epsilon\n",
        "        delta_T = tf.reduce_max(tf.abs(self.T - new_transition)) < self.epsilon\n",
        "        delta_E = tf.reduce_max(tf.abs(self.E - new_emission)) < self.epsilon\n",
        "\n",
        "        return tf.logical_and(tf.logical_and(delta_T0, delta_T), delta_E)\n",
        "        \n",
        "    def forward_backward(self, obs_prob_seq):\n",
        "        \"\"\"\n",
        "        runs forward backward algorithm on observation sequence\n",
        "        Arguments\n",
        "        ---------\n",
        "        - obs_seq : matrix of size N by S, where N is number of timesteps and\n",
        "            S is the number of states\n",
        "        Returns\n",
        "        -------\n",
        "        - forward : matrix of size N by S representing\n",
        "            the forward probability of each state at each time step\n",
        "        - backward : matrix of size N by S representing\n",
        "            the backward probability of each state at each time step\n",
        "        - posterior : matrix of size N by S representing\n",
        "            the posterior probability of each state at each time step\n",
        "        \"\"\"\n",
        "        obs_prob_list_for = tf.split(obs_prob_seq, self.N, 0)\n",
        "        \n",
        "        with tf.name_scope('forward_belief_propagation'):\n",
        "            # forward belief propagation\n",
        "            self._forward(obs_prob_list_for)\n",
        "\n",
        "        obs_prob_seq_rev = tf.reverse(obs_prob_seq, [True, False])\n",
        "        obs_prob_list_back = tf.split(obs_prob_seq_rev, self.N, 0)\n",
        "\n",
        "        with tf.name_scope('backward_belief_propagation'):\n",
        "            # backward belief propagation\n",
        "            self._backward(obs_prob_list_back)\n",
        "        \n",
        "    def expectation_maximization_step(self, x):\n",
        "        \n",
        "        # probability of emission sequence\n",
        "        obs_prob_seq = tf.gather(self.E, x)\n",
        "\n",
        "        with tf.name_scope('Forward_Backward'):\n",
        "            self.forward_backward(obs_prob_seq)\n",
        "\n",
        "        with tf.name_scope('Re_estimate_transition'):\n",
        "            new_T0, new_transition = self.re_estimate_transition(x)\n",
        "        \n",
        "        with tf.name_scope('Re_estimate_emission'):\n",
        "            new_emission = self.re_estimate_emission(x)\n",
        "\n",
        "        with tf.name_scope('Check_Convergence'):\n",
        "            converged = self.check_convergence(new_T0, new_transition, new_emission)\n",
        "\n",
        "        with tf.name_scope('Update_parameters'):\n",
        "            self.T0 = tf.assign(self.T0, new_T0)\n",
        "            self.E = tf.assign(self.E, new_emission)\n",
        "            self.T = tf.assign(self.T, new_transition)\n",
        "            #self.count = tf.assign_add(self.count, 1)\n",
        "             \n",
        "            with tf.name_scope('histogram_summary'):\n",
        "                _ = tf.summary.histogram(self.T0.name, self.T0)\n",
        "                _ = tf.summary.histogram(self.T.name, self.T)\n",
        "                _ = tf.summary.histogram(self.E.name, self.E)\n",
        "        return converged\n",
        "        \n",
        "    \n",
        "    def Baum_Welch_EM(self, obs_seq):\n",
        "        \n",
        "        with tf.name_scope('Input_Observed_Sequence'):\n",
        "            # length of observed sequence\n",
        "            self.N = len(obs_seq)\n",
        "\n",
        "            # shape of Variables\n",
        "            shape = [self.N, self.S]\n",
        "\n",
        "            # observed sequence\n",
        "            x = tf.constant(obs_seq, dtype=tf.int32, name='observation_sequence')\n",
        "        \n",
        "        with tf.name_scope('Initialize_variables'):\n",
        "            # initialize variables\n",
        "            self.initialize_forw_back_variables(shape)\n",
        "        \n",
        "        converged = tf.cast(False, tf.bool)\n",
        "        #self.count = tf.Variable(tf.constant(0))\n",
        "        \n",
        "        with tf.name_scope('Train_Baum_Welch'):\n",
        "            for i in range(self.maxStep):\n",
        "                \n",
        "                with tf.name_scope('EM_step-%s' %i):\n",
        "                    converged = self.expectation_maximization_step(x)\n",
        "\n",
        "#         TF while_loop op is buggy, should be fixed in future release\n",
        "#         def loop_conditions(converged, obs_seq):\n",
        "#             cond_1 = tf.logical_not(converged)\n",
        "#             cond_2 = tf.less(self.count, self.maxStep)\n",
        "#             return tf.logical_or(cond_1, cond_2)\n",
        "        \n",
        "#         def body(converged, obs_seq):\n",
        "#             return self.expectation_maximization_step(obs_seq)\n",
        "        \n",
        "#         while_params = [converged, obs_seq]\n",
        "#         c = tf.while_loop(loop_conditions, body, while_params)\n",
        "      \n",
        "        return converged\n",
        "    \n",
        "    def run_Baum_Welch_EM(self, obs_seq, summary=False, monitor_state_1=False):\n",
        "        \n",
        "        converged = self.Baum_Welch_EM(obs_seq)\n",
        "        \n",
        "        # Build the summary operation based on the TF collection of Summaries.\n",
        "        summary_op = tf.summary.merge_all()\n",
        "        \n",
        "        with tf.Session() as sess:\n",
        "            sess.run(tf.global_variables_initializer())\n",
        "            trans0, transition, emission, c = sess.run([self.T0, self.T, self.E, converged])\n",
        "            \n",
        "            if monitor_state_1:\n",
        "                self.state_summary = np.array([sess.run(g) for g in self.prob_state_1])\n",
        "            \n",
        "            if summary:\n",
        "                # Instantiate a SummaryWriter to output summaries and the Graph.\n",
        "                summary_writer = tf.train.SummaryWriter('logs/', graph=sess.graph)\n",
        "                \n",
        "                summary_str = sess.run(summary_op)\n",
        "                summary_writer.add_summary(summary_str)\n",
        "\n",
        "            return trans0, transition, emission, c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lu0456TaGSdA",
        "colab_type": "text"
      },
      "source": [
        "## Viterbi Example\n",
        "\n",
        "Let's consider the following simple HMM.\n",
        "* Composed of 2 hidden states: Healthy and Fever.\n",
        "* Composed of 3 possible observation: Normal, Cold, Dizzy\n",
        "\n",
        "The model can then be used to predict if a person is feverish at every timestep from a given observation sequence. There are several paths through the hidden states (Healthy and Fever) that lead to the given sequence, but they do not have the same probability.\n",
        "\n",
        "The Viterbi algorithm is a dynamical programming algorithm that allows us to compute the most probable path. This package will compute recursively the probability of the most probable path. \n",
        "\n",
        "Note: for the calculations, it is convenient to use the log of the probabilities. Indeed, this allows us to compute sums instead of products, which is more efficient and accurate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BERLzHBrGSdB",
        "colab_type": "text"
      },
      "source": [
        "![](https://github.com/apester/HiddenMarkovModel_TensorFlow/blob/master/images/Viterbi.gif?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-AD3UEiGSdB",
        "colab_type": "text"
      },
      "source": [
        "### Model Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1gTL6P2GSdC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p0 = np.array([0.6, 0.4])\n",
        "\n",
        "emi = np.array([[0.5, 0.1],\n",
        "                [0.4, 0.3],\n",
        "                [0.1, 0.6]])\n",
        "\n",
        "trans = np.array([[0.7, 0.3],\n",
        "                  [0.4, 0.6]])\n",
        "\n",
        "states = {0:'Healthy', 1:'Fever'}\n",
        "obs = {0:'normal', 1:'cold', 2:'dizzy'}\n",
        "\n",
        "obs_seq = np.array([0, 0, 1, 2, 2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGe1ofSgGSdE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_p0 = pd.DataFrame(p0, index=[\"Healthy\", \"Fever\"], columns=[\"Prob\"])\n",
        "df_emi = pd.DataFrame(emi, index=[\"Normal\", \"Cold\", \"Dizzy\"], columns=[\"Healthy\", \"Fever\"])\n",
        "df_trans = pd.DataFrame(trans, index=[\"fromHealthy\", \"fromFever\"], columns=[\"toHealthy\", \"toFever\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJW0W5DuGSdF",
        "colab_type": "text"
      },
      "source": [
        "### Inital state probability"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkvUWZ0kGSdG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "2b8a3c7b-bed4-4376-ef56-79e12b0caacd"
      },
      "source": [
        "df_p0"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Prob\n",
              "Healthy   0.6\n",
              "Fever     0.4"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Healthy</th>\n",
              "      <td>0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fever</th>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6YSP3p9GSdI",
        "colab_type": "text"
      },
      "source": [
        "### Transition Probability Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "mT1jIkYHGSdJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "a8cb8c5a-074d-4518-8247-ee2ec91e9734"
      },
      "source": [
        "df_trans"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             toHealthy  toFever\n",
              "fromHealthy        0.7      0.3\n",
              "fromFever          0.4      0.6"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>toHealthy</th>\n",
              "      <th>toFever</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>fromHealthy</th>\n",
              "      <td>0.7</td>\n",
              "      <td>0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fromFever</th>\n",
              "      <td>0.4</td>\n",
              "      <td>0.6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nD6kJrgAGSdL",
        "colab_type": "text"
      },
      "source": [
        "### Emission Probability Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfzCvTIkGSdL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "b4bacbff-539e-4079-9587-d72418572c5c"
      },
      "source": [
        "df_emi"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Healthy  Fever\n",
              "Normal      0.5    0.1\n",
              "Cold        0.4    0.3\n",
              "Dizzy       0.1    0.6"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Healthy</th>\n",
              "      <th>Fever</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Normal</th>\n",
              "      <td>0.5</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Cold</th>\n",
              "      <td>0.4</td>\n",
              "      <td>0.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Dizzy</th>\n",
              "      <td>0.1</td>\n",
              "      <td>0.6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAmcUuiJGSdN",
        "colab_type": "text"
      },
      "source": [
        "### Run Viterbi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "_iFwQHJeGSdN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "outputId": "a2248dd0-1155-43a4-d706-a210cce143f1"
      },
      "source": [
        "model =  HiddenMarkovModel(trans, emi, p0)\n",
        "states_seq, state_prob = model.run_viterbi(obs_seq, summary=True)\n",
        "\n",
        "print(\"Observation sequence: \", [obs[o] for o in obs_seq])\n",
        "df = pd.DataFrame(state_prob.T, index=[\"Healthy\", \"Fever\"])\n",
        "df.style.apply(highlight_max, axis=0)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0609 08:27:49.842180 140050928510848 deprecation.py:323] From /tensorflow-1.15.2/python2.7/tensorflow_core/python/util/tf_should_use.py:198: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
            "Instructions for updating:\n",
            "Use `tf.global_variables_initializer` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Observation sequence:  ['normal', 'normal', 'cold', 'dizzy', 'dizzy']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f5fbf1acb90>"
            ],
            "text/html": [
              "<style  type=\"text/css\" >\n",
              "    #T_1ae2c0bc_aa2b_11ea_9f97_0242ac1c0002row0_col0 {\n",
              "            background-color:  yellow;\n",
              "        }    #T_1ae2c0bc_aa2b_11ea_9f97_0242ac1c0002row0_col1 {\n",
              "            background-color:  yellow;\n",
              "        }    #T_1ae2c0bc_aa2b_11ea_9f97_0242ac1c0002row0_col2 {\n",
              "            background-color:  yellow;\n",
              "        }    #T_1ae2c0bc_aa2b_11ea_9f97_0242ac1c0002row1_col3 {\n",
              "            background-color:  yellow;\n",
              "        }    #T_1ae2c0bc_aa2b_11ea_9f97_0242ac1c0002row1_col4 {\n",
              "            background-color:  yellow;\n",
              "        }</style><table id=\"T_1ae2c0bc_aa2b_11ea_9f97_0242ac1c0002\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >0</th>        <th class=\"col_heading level0 col1\" >1</th>        <th class=\"col_heading level0 col2\" >2</th>        <th class=\"col_heading level0 col3\" >3</th>        <th class=\"col_heading level0 col4\" >4</th>    </tr></thead><tbody>\n",
              "                <tr>\n",
              "                        <th id=\"T_1ae2c0bc_aa2b_11ea_9f97_0242ac1c0002level0_row0\" class=\"row_heading level0 row0\" >Healthy</th>\n",
              "                        <td id=\"T_1ae2c0bc_aa2b_11ea_9f97_0242ac1c0002row0_col0\" class=\"data row0 col0\" >0.3</td>\n",
              "                        <td id=\"T_1ae2c0bc_aa2b_11ea_9f97_0242ac1c0002row0_col1\" class=\"data row0 col1\" >0.105</td>\n",
              "                        <td id=\"T_1ae2c0bc_aa2b_11ea_9f97_0242ac1c0002row0_col2\" class=\"data row0 col2\" >0.0294</td>\n",
              "                        <td id=\"T_1ae2c0bc_aa2b_11ea_9f97_0242ac1c0002row0_col3\" class=\"data row0 col3\" >0.002058</td>\n",
              "                        <td id=\"T_1ae2c0bc_aa2b_11ea_9f97_0242ac1c0002row0_col4\" class=\"data row0 col4\" >0.00021168</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_1ae2c0bc_aa2b_11ea_9f97_0242ac1c0002level0_row1\" class=\"row_heading level0 row1\" >Fever</th>\n",
              "                        <td id=\"T_1ae2c0bc_aa2b_11ea_9f97_0242ac1c0002row1_col0\" class=\"data row1 col0\" >0.04</td>\n",
              "                        <td id=\"T_1ae2c0bc_aa2b_11ea_9f97_0242ac1c0002row1_col1\" class=\"data row1 col1\" >0.009</td>\n",
              "                        <td id=\"T_1ae2c0bc_aa2b_11ea_9f97_0242ac1c0002row1_col2\" class=\"data row1 col2\" >0.00945</td>\n",
              "                        <td id=\"T_1ae2c0bc_aa2b_11ea_9f97_0242ac1c0002row1_col3\" class=\"data row1 col3\" >0.005292</td>\n",
              "                        <td id=\"T_1ae2c0bc_aa2b_11ea_9f97_0242ac1c0002row1_col4\" class=\"data row1 col4\" >0.00190512</td>\n",
              "            </tr>\n",
              "    </tbody></table>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "kEA86FO8GSdP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7ab1387f-8b5c-4040-b7b7-71cd0cbf7e11"
      },
      "source": [
        "print(\"Most likely States: \",[states[s] for s in states_seq])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Most likely States:  ['Healthy', 'Healthy', 'Healthy', 'Fever', 'Fever']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dt-VqUwqGSdR",
        "colab_type": "text"
      },
      "source": [
        "## Visualize the Computation Graph with Tensorboard\n",
        "\n",
        "Each nodes expends into an exploded view of the computation graph generated by Tensorflow.\n",
        "Check it out!\n",
        "\n",
        "**Run Tensorboard on command line :**\n",
        "\n",
        "> tensorboard --logdir= [graph/file/location](https://github.com/MarvinBertin/HiddenMarkovModel_TensorFlow/tree/master/TensorBoard/Viterbi)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMvb5TEHGSdR",
        "colab_type": "text"
      },
      "source": [
        "![](https://github.com/apester/HiddenMarkovModel_TensorFlow/blob/master/images/viterbi.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i50zQc88GSdS",
        "colab_type": "text"
      },
      "source": [
        "# Forward - Backward Algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ch1-GGMCGSdS",
        "colab_type": "text"
      },
      "source": [
        "** Overview **\n",
        "* The goal of the forward-backward algorithm is to find the conditional distribution over hidden states given the data.\n",
        "\n",
        "* It is used to find the most likely state for any point in time.\n",
        "* It cannot, however, be used to find the most likely sequence of states (see Viterbi)\n",
        "\n",
        "**The forward–backward algorithm:**\n",
        "* Inference algorithm for hidden Markov models.\n",
        "* Computes posterior marginals of all hidden state variables given a sequence of observations/emissions.\n",
        "* Computes, for all hidden state variables $S_k \\in \\{S_1, \\dots, S_t\\}$, the distribution $P(S_k\\ |\\ o_{1:t})$.\n",
        "* This inference task is usually called smoothing.\n",
        "* The algorithm makes use of the principle of dynamic programming to compute efficiently the values that are required to obtain the posterior marginal distributions in two passes.\n",
        "* The first pass goes forward in time while the second goes backward in time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFNcqT7rGSdS",
        "colab_type": "text"
      },
      "source": [
        "### Visualization of the Forward and Backward Messages\n",
        "* Each message is a table that indicates what the node at the start point believes about the node at the end point."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCLohRRWGSdT",
        "colab_type": "text"
      },
      "source": [
        "![](https://github.com/apester/HiddenMarkovModel_TensorFlow/blob/master/images/FB1.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aB8JwyObGSdT",
        "colab_type": "text"
      },
      "source": [
        "### Computing Message Passing\n",
        "**Forward message**\n",
        "* $α_k$ represents a message from $k − 1$ to $k$ that includes $p_{Y|X}(y_k|x_k)$.\n",
        "<br>\n",
        "\n",
        "** Backward message** \n",
        "* $β_k$ represents a message from $k + 1$ to $k$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTmxTI6vGSdU",
        "colab_type": "text"
      },
      "source": [
        "![](https://github.com/apester/HiddenMarkovModel_TensorFlow/blob/master/images/FB3.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvEmGha4GSdU",
        "colab_type": "text"
      },
      "source": [
        "### Probability interpretation of message passing\n",
        "\n",
        "**Forward message**\n",
        "* The probability of ending up in any particular state given the first k observations in the sequence.\n",
        "<br>\n",
        "\n",
        "\n",
        "** Backward message** \n",
        "* The probability of observing the remaining observations given any starting point k"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iB406gyvGSdV",
        "colab_type": "text"
      },
      "source": [
        "![](https://github.com/apester/HiddenMarkovModel_TensorFlow/blob/master/images/eq3.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80PBUSiTGSdV",
        "colab_type": "text"
      },
      "source": [
        "### Smoothing Step\n",
        "** Represent the conditional probability of being in state $S_i$ at time $t$ given the observation sequence**\n",
        "\n",
        "* The initial forward $α$ message is initialized to $α_1(x_1) = P_{X_1}(x_1)P_{Y|X}(y_1|x_1)$.\n",
        "* To obtain a marginal distribution, we simply multiply the messages together and normalize:\n",
        "* The smoothing step allows the algorithm to take into account any past observations of output for computing more accurate results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gt7mhJURGSdV",
        "colab_type": "text"
      },
      "source": [
        "![](https://github.com/apester/HiddenMarkovModel_TensorFlow/blob/master/images/eq4.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_ATf3TIGSdW",
        "colab_type": "text"
      },
      "source": [
        "### Visualizing Message Passing for  $m_{2→3}(x_3)$\n",
        "In order for node 2 to summarize its belief about $X_3$, it must incorporate: \n",
        "* The previous message $m_{1→2}(x_2)$\n",
        "* Its observation $p_{Y|X}(y_2|x_2)$\n",
        "* The relationship $W(x_3|x_2)$ between $X_2$ and $X_3$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjOPC5g4GSdW",
        "colab_type": "text"
      },
      "source": [
        "![](https://github.com/apester/HiddenMarkovModel_TensorFlow/blob/master/images/FB4.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNoURuYiGSdW",
        "colab_type": "text"
      },
      "source": [
        "## Forward-Backward Example\n",
        "\n",
        "Let's condiser a situation where you work in a shopping mall with no views to the outside.\n",
        "You wish to infer the weather outside (Rain, No Rain) at the present moment, given only obervations of passerby with or without an umbrella."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25eHzFuWGSdX",
        "colab_type": "text"
      },
      "source": [
        "### Define Model Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ez1CWc82GSdX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p0 = np.array([0.5, 0.5])\n",
        "\n",
        "emi = np.array([[0.9, 0.2],\n",
        "                [0.1, 0.8]])\n",
        "\n",
        "trans = np.array([[0.7, 0.3],\n",
        "                  [0.3, 0.7]])\n",
        "\n",
        "states = {0:'rain', 1:'no_rain'}\n",
        "obs = {0:'umbrella', 1:'no_umbrella'}\n",
        "\n",
        "obs_seq = np.array([1, 1, 0, 0, 0, 1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "FLZ6wQS5GSdZ",
        "colab_type": "text"
      },
      "source": [
        "## Run Forward-Backward"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOmvUAZNLqtT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "__author__ = 'MarvinBertin'\n",
        "\n",
        "\"Inspired by Zach Dwiel's HMM implementation\"\n",
        "\n",
        "class HiddenMarkovModel_FB(object):\n",
        "\n",
        "    \"\"\"\n",
        "    Hidden Markov Model Class\n",
        "    Parameters:\n",
        "    -----------\n",
        "    \n",
        "    - S: Number of states.\n",
        "    - T: Transition matrix of size S by S\n",
        "         stores probability from state i to state j.\n",
        "    - E: Emission matrix of size S by N (number of observations)\n",
        "         stores the probability of observing  O_j  from state  S_i. \n",
        "    - T0: Initial state probabilities of size S.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, T, E, T0):\n",
        "        # Number of states\n",
        "        self.S = T.shape[0]\n",
        "        \n",
        "        # Emission probability\n",
        "        self.E = tf.constant(E, name='emission_matrix')\n",
        "\n",
        "        # Transition matrix\n",
        "        self.T = tf.constant(T, name='transition_matrix')\n",
        "\n",
        "        # Initial state vector\n",
        "        self.T0 = tf.constant(T0, name='inital_state_vector')\n",
        "\n",
        "    def initialize_path_variables(self, shape):\n",
        "        \n",
        "        pathStates = tf.Variable(tf.zeros(shape, dtype=tf.int64), name='States_matrix')\n",
        "        pathScores = tf.Variable(tf.zeros(shape, dtype=tf.float64), name='Score_matrix')\n",
        "        states_seq = tf.Variable(tf.zeros([shape[0]], dtype=tf.int64), name='States_sequence')\n",
        "        return pathStates, pathScores, states_seq\n",
        "    \n",
        "    def belief_propagation(self, scores):\n",
        "        \n",
        "        scores_reshape = tf.reshape(scores, (-1,1))\n",
        "        return tf.add(scores_reshape, tf.log(self.T))\n",
        "    \n",
        "    def viterbi_inference(self, obs_seq):\n",
        "        \n",
        "        # length of observed sequence\n",
        "        self.N = len(obs_seq)\n",
        "        \n",
        "        # shape path Variables\n",
        "        shape = [self.N, self.S]\n",
        "        \n",
        "        # observed sequence\n",
        "        x = tf.constant(obs_seq, name='observation_sequence')\n",
        "        \n",
        "        # Initialize variables\n",
        "        pathStates, pathScores, states_seq = self.initialize_path_variables(shape)       \n",
        "        \n",
        "        # log probability of emission sequence\n",
        "        obs_prob_seq = tf.log(tf.gather(self.E, x))\n",
        "        obs_prob_list = tf.split(0, self.N, obs_prob_seq)\n",
        "\n",
        "        # initialize with state starting log-priors\n",
        "        pathScores = tf.scatter_update(pathScores, 0, tf.log(self.T0) + tf.squeeze(obs_prob_list[0]))\n",
        "            \n",
        "        \n",
        "        for step, obs_prob in enumerate(obs_prob_list[1:]):\n",
        "            \n",
        "            # propagate state belief\n",
        "            belief = self.belief_propagation(pathScores[step, :])\n",
        "\n",
        "            # the inferred state by maximizing global function\n",
        "            # and update state and score matrices \n",
        "            pathStates = tf.scatter_update(pathStates, step + 1, tf.argmax(belief, 0))\n",
        "            pathScores = tf.scatter_update(pathScores, step + 1, tf.reduce_max(belief, 0) + tf.squeeze(obs_prob))\n",
        "\n",
        "        # infer most likely last state\n",
        "        states_seq = tf.scatter_update(states_seq, self.N-1, tf.argmax(pathScores[self.N-1, :], 0))\n",
        "        \n",
        "        for step in range(self.N - 1, 0, -1):\n",
        "            # for every timestep retrieve inferred state\n",
        "            state = states_seq[step]\n",
        "            idx = tf.reshape(tf.pack([step, state]), [1, -1])\n",
        "            state_prob = tf.gather_nd(pathStates, idx)\n",
        "            states_seq = tf.scatter_update(states_seq, step - 1,  state_prob[0])\n",
        "\n",
        "        return states_seq, tf.exp(pathScores) # turn scores back to probabilities\n",
        "    \n",
        "    def run_viterbi(self, obs_seq):\n",
        "        with tf.Session() as sess:\n",
        "            \n",
        "            state_graph, state_prob_graph = self.viterbi_inference(obs_seq)\n",
        "            sess.run(tf.initialize_all_variables())\n",
        "            states_seq, state_prob = sess.run([state_graph, state_prob_graph])\n",
        "\n",
        "        return states_seq, state_prob \n",
        "    \n",
        "    \n",
        "    def initialize_variables(self, shape, shape_ext):\n",
        "        self.forward = tf.Variable(tf.zeros(shape_ext, dtype=tf.float64), name='forward')\n",
        "        self.backward = tf.Variable(tf.zeros(shape_ext, dtype=tf.float64), name='backward')\n",
        "        self.posterior = tf.Variable(tf.zeros(shape, dtype=tf.float64), name='posteriror')\n",
        "\n",
        "\n",
        "    def _forward(self, obs_prob_seq):\n",
        "        # initialize with state starting priors\n",
        "        self.forward = tf.scatter_update(self.forward, 0, self.T0)\n",
        "\n",
        "        # propagate belief\n",
        "        for step in range(self.N):\n",
        "            # previous state probability\n",
        "            prev_prob = tf.reshape(self.forward[step, :], [1, -1])\n",
        "            # transition prior\n",
        "            prior_prob = tf.matmul(prev_prob, self.T)\n",
        "            # forward belief propagation\n",
        "            forward_score = tf.multiply(prior_prob, tf.cast(obs_prob_seq[step, :], tf.float64))\n",
        "            # Normalize score into a probability\n",
        "            forward_prob = tf.reshape(forward_score / tf.reduce_sum(forward_score), [-1])\n",
        "            # Update forward matrix\n",
        "            self.forward = tf.scatter_update(self.forward, step + 1, forward_prob)\n",
        "\n",
        "        # remove initial probability\n",
        "        #self.forward = tf.slice(self.forward, [1,0], [self.N, self.S]) \n",
        "        \n",
        "\n",
        "    def _backward(self, obs_prob_seq):\n",
        "        # initialize with state ending priors\n",
        "        self.backward = tf.scatter_update(self.backward, self.N, tf.ones([self.S], dtype=tf.float64)) \n",
        "\n",
        "        for step in range(self.N, 0, -1):\n",
        "            # next state probability\n",
        "            next_prob = tf.reshape(self.backward[step, :], [-1, 1])\n",
        "            # observation emission probabilities\n",
        "            obs_prob = tf.diag(obs_prob_seq[step - 1, :])\n",
        "            # transition prior\n",
        "            prior_prob = tf.matmul(self.T, obs_prob)\n",
        "            # backward belief propagation\n",
        "            backward_score = tf.matmul(prior_prob, next_prob)\n",
        "            # Normalize score into a probability\n",
        "            backward_prob = tf.reshape(backward_score / tf.reduce_sum(backward_score), [-1])\n",
        "\n",
        "            # Update backward matrix\n",
        "            self.backward = tf.scatter_update(self.backward, step - 1, backward_prob)\n",
        "        \n",
        "        # remove final probability\n",
        "        #self.backward = tf.slice(self.backward, [0,0], [self.N, self.S])\n",
        "\n",
        "        \n",
        "    def forward_backward(self, obs_seq):\n",
        "        \"\"\"\n",
        "        runs forward backward algorithm on observation sequence\n",
        "        Arguments\n",
        "        ---------\n",
        "        - obs_seq : matrix of size N by S, where N is number of timesteps and\n",
        "            S is the number of states\n",
        "        Returns\n",
        "        -------\n",
        "        - forward : matrix of size N by S representing\n",
        "            the forward probability of each state at each time step\n",
        "        - backward : matrix of size N by S representing\n",
        "            the backward probability of each state at each time step\n",
        "        - posterior : matrix of size N by S representing\n",
        "            the posterior probability of each state at each time step\n",
        "        \"\"\"\n",
        "\n",
        "        # length of observed sequence\n",
        "        self.N = len(obs_seq)\n",
        "\n",
        "        # shape of Variables\n",
        "        shape = [self.N, self.S]\n",
        "        shape_ext = [self.N+1, self.S]\n",
        "        \n",
        "        # observed sequence\n",
        "        x = tf.constant(obs_seq, dtype=tf.int32, name='observation_sequence')\n",
        "        \n",
        "        # initialize variables\n",
        "        self.initialize_variables(shape, shape_ext)\n",
        "        \n",
        "        # probability of emission sequence\n",
        "        obs_prob_seq = tf.gather(self.E, x)\n",
        "        \n",
        "        # forward belief propagation\n",
        "        self._forward(obs_prob_seq)\n",
        "        \n",
        "        # backward belief propagation\n",
        "        self._backward(obs_prob_seq)\n",
        "\n",
        "        # posterior score\n",
        "        self.posterior = tf.multiply(self.forward, self.backward)\n",
        "        \n",
        "        # marginal per timestep\n",
        "        marginal = tf.reduce_sum(self.posterior, 1)\n",
        "        \n",
        "        # Normalize porsterior into probabilities\n",
        "        self.posterior = self.posterior / tf.reshape(marginal, [-1, 1])\n",
        "\n",
        "        return self.forward, self.backward, self.posterior\n",
        "    \n",
        "    def run_forward_backward(self, obs_seq):\n",
        "        with tf.Session() as sess:\n",
        "            \n",
        "            forward, backward, posterior = self.forward_backward(obs_seq)\n",
        "            sess.run(tf.initialize_all_variables())\n",
        "            return sess.run([forward, backward, posterior])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4dn36uBGSdZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "caa2be77-9353-4b67-a3a6-23f3b4cc8430"
      },
      "source": [
        "# from forward_bakward import HiddenMarkovModel_FB\n",
        "model =  HiddenMarkovModel_FB(trans, emi, p0)\n",
        "\n",
        "results = model.run_forward_backward(obs_seq)\n",
        "result_list = [\"Forward\", \"Backward\", \"Posterior\"]\n",
        "\n",
        "for state_prob, path in zip(results, result_list) :\n",
        "    inferred_states = np.argmax(state_prob, axis=1)\n",
        "    print()\n",
        "    print(path)\n",
        "    dptable(state_prob)\n",
        "    print()\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"Most likely Final State: \",states[inferred_states[-1]])\n",
        "print(\"=\"*60)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Forward\n",
            "       0        1        2        3        4        5        6\n",
            "rain: 0.50000 0.11111 0.06163 0.68386 0.85819 0.89029 0.19256\n",
            "no_rain: 0.50000 0.88888 0.93837 0.31613 0.14180 0.10971 0.80743\n",
            "\n",
            "\n",
            "Backward\n",
            "       0        1        2        3        4        5        6\n",
            "rain: 0.32814 0.37709 0.65637 0.64477 0.58110 0.34444 1.00000\n",
            "no_rain: 0.67186 0.62290 0.34363 0.35522 0.41889 0.65555 1.00000\n",
            "\n",
            "\n",
            "Posterior\n",
            "       0        1        2        3        4        5        6\n",
            "rain: 0.32814 0.07035 0.11146 0.79701 0.89357 0.81002 0.19256\n",
            "no_rain: 0.67186 0.92965 0.88853 0.20298 0.10643 0.18997 0.80743\n",
            "\n",
            "============================================================\n",
            "Most likely Final State:  no_rain\n",
            "============================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mQSn0d4GSdb",
        "colab_type": "text"
      },
      "source": [
        "## Baum Welch Algorithm\n",
        "\n",
        "Baum–Welch algorithm is used to infer unknown parameters of a Hidden Markov Model.\n",
        "\n",
        "**Model Parameters:**\n",
        "* Initial State Probabilities\n",
        "* Transition Matrix\n",
        "* Emission Matrix\n",
        "\n",
        "\n",
        "** Expectation-Maximization ** <br>\n",
        "It makes use of the forward-backward algorithm to update the hypothesis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfLzH6xyGSdb",
        "colab_type": "text"
      },
      "source": [
        "![](https://github.com/apester/HiddenMarkovModel_TensorFlow/blob/master/images/EM3.jpg?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIAIZyQIGSdb",
        "colab_type": "text"
      },
      "source": [
        "## Visualizing Expectation-Maximization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqHa3tkTGSdc",
        "colab_type": "text"
      },
      "source": [
        "![](https://github.com/apester/HiddenMarkovModel_TensorFlow/blob/master/images/EM1.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b61Uw7bZGSdc",
        "colab_type": "text"
      },
      "source": [
        "### Compute Variable Updates (Expectation step)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSMwBL0VGSdc",
        "colab_type": "text"
      },
      "source": [
        "**Calculate the temporary variables, according to Bayes' theorem:** <br>\n",
        "It's the probability of being in state $i$ at time $t$ given the observed sequence $Y$ and the parameters $\\theta$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PzL0b-9GSdd",
        "colab_type": "text"
      },
      "source": [
        "$$\\gamma_i(t)=P(X_t=i|Y,\\theta) = \\frac{\\alpha_i(t)\\beta_i(t)}{\\sum_{j=1}^N \\alpha_j(t)\\beta_j(t)}$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YO-sDMmPGSdd",
        "colab_type": "text"
      },
      "source": [
        "The probability of being in state $i$ and $j$ at times $t$ and $t+1$ respectively given the observed sequence $Y$ and parameters $\\theta$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdfDqvHzGSdd",
        "colab_type": "text"
      },
      "source": [
        "$$\\xi_{ij}(t)=P(X_t=i,X_{t+1}=j|Y,\\theta)=\\frac{\\alpha_i(t) a_{ij} \\beta_j(t+1) b_j(y_{t+1})}{\\sum_{k=1}^N \\alpha_k(T)}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZF0aNnpGSde",
        "colab_type": "text"
      },
      "source": [
        "**Update Inital State Probability**<br>\n",
        "It's expected frequency spent in state i at time 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tro3ubbSGSde",
        "colab_type": "text"
      },
      "source": [
        "$$\\pi_i^* = \\gamma_i(1)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S73nkze2GSde",
        "colab_type": "text"
      },
      "source": [
        "** Update Transition Matrix** <br>\n",
        "It's the expected number of transitions from state $i$ to state $j$ compared to the expected total number of transitions away from state $i$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kxt4lAKGGSdf",
        "colab_type": "text"
      },
      "source": [
        "$$ a_{ij}^*=\\frac{\\sum^{T-1}_{t=1}\\xi_{ij}(t)}{\\sum^{T-1}_{t=1}\\gamma_i(t)}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYdJgnY2GSdf",
        "colab_type": "text"
      },
      "source": [
        "** Update Emission Matrix** <br>\n",
        "It's the expected number of times the output observations have been equal to $v_k$ while in state $i$ over the expected total number of times in state $i$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UkDNv8mGSdf",
        "colab_type": "text"
      },
      "source": [
        "$$b_i^*(v_k)=\\frac{\\sum^T_{t=1} 1_{y_t=v_k} \\gamma_i(t)}{\\sum^T_{t=1} \\gamma_i(t)}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ve_fzonGSdf",
        "colab_type": "text"
      },
      "source": [
        "**Note:**\n",
        "* It is possible to over-fit a particular data set. That is $P(Y|\\theta_{final})>P(Y|\\theta_{true})$.\n",
        "* The algorithm also does not guarantee a global maximum."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLHqrdESGSdg",
        "colab_type": "text"
      },
      "source": [
        "## Run Baum-Welch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jm6iwUJKGSdh",
        "colab_type": "text"
      },
      "source": [
        "### Data Generator Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PX4t7pcGSdh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_HMM_observation(num_obs, pi, T, E):\n",
        "    def drawFrom(probs):\n",
        "        return np.where(np.random.multinomial(1,probs) == 1)[0][0]\n",
        "\n",
        "    obs = np.zeros(num_obs)\n",
        "    states = np.zeros(num_obs)\n",
        "    states[0] = drawFrom(pi)\n",
        "    obs[0] = drawFrom(E[:, int(states[0])])\n",
        "    for t in range(1,num_obs):\n",
        "        states[t] = drawFrom(T[int(states[t-1]),:])\n",
        "        obs[t] = drawFrom(E[:, int(states[t])])\n",
        "    return obs, states"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mLUUk0DGSdj",
        "colab_type": "text"
      },
      "source": [
        "### True Parameters that Generated the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNe-fGwiGSdk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "True_pi = np.array([0.5, 0.5])\n",
        "\n",
        "True_T = np.array([[0.85, 0.15],\n",
        "                  [0.12, 0.88]])\n",
        "\n",
        "True_E = np.array([[0.8, 0.0],\n",
        "                   [0.1, 0.0],\n",
        "                   [0.1, 1.0]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vLPm7ZaGSdn",
        "colab_type": "text"
      },
      "source": [
        "### Generate a Sample of 50 Observations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kS-4DCrIGSdn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "obs_seq, states = generate_HMM_observation(50, True_pi, True_T, True_E)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sxd0a0HfGSdp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b873edba-5d8e-409c-a32a-e6d61fd0e610"
      },
      "source": [
        "print(\"First 10 Obersvations:  \", obs_seq[:18])\n",
        "print(\"First 10 Hidden States: \", states[:18])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First 10 Obersvations:   [2. 2. 2. 2. 0. 0. 0. 2. 2. 2. 2. 2. 2. 2. 0. 2. 0. 2.]\n",
            "First 10 Hidden States:  [1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8nOO5b-GSdq",
        "colab_type": "text"
      },
      "source": [
        "### Initialize to Arbitrary Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elmJoe0uGSdr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init_pi = np.array([0.5, 0.5])\n",
        "\n",
        "init_T = np.array([[0.5, 0.5],\n",
        "                  [0.5, 0.5]])\n",
        "\n",
        "init_E = np.array([[0.3, 0.2],\n",
        "                   [0.3, 0.5],\n",
        "                   [0.4, 0.3]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GKy-EGPGSds",
        "colab_type": "text"
      },
      "source": [
        "### Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoMVwxpVGSds",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model =  HiddenMarkovModel(init_T, init_E, init_pi, epsilon=0.0001, maxStep=12)\n",
        "\n",
        "trans0, transition, emission, c = model.run_Baum_Welch_EM(obs_seq, summary=False, monitor_state_1=True)\n",
        "\n",
        "print(\"Transition Matrix: \")\n",
        "print(transition)\n",
        "print()\n",
        "print(\"Emission Matrix: \")\n",
        "print(emission)\n",
        "print()\n",
        "print(\"Reached Convergence: \")\n",
        "print(c)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vc_xyS3qGSdv",
        "colab_type": "text"
      },
      "source": [
        "### Plot of Probability of State 1 over multiple training steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXxW5_RKGSdv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(15,6))\n",
        "plt.plot(1-model.state_summary[[0, 4, 6, 8, 9, 10]].T)\n",
        "plt.ylim(-0.1,1.1)\n",
        "plt.title('Probability State=1 over time')\n",
        "plt.xlabel('Time')\n",
        "plt.draw()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqXI5VusGSdw",
        "colab_type": "text"
      },
      "source": [
        "### Plot of True State over Guess Probability of State=1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJqamMiiGSdx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(15,6))\n",
        "plt.plot(states.T,'-o',alpha=0.7)\n",
        "plt.plot(1-model.state_summary[-2].T, '-o',alpha=0.7)\n",
        "plt.legend(('True State','Guessed Probability of State=1'), loc = 'right')\n",
        "plt.ylim(-0.1,1.1)\n",
        "plt.xlabel('Time')\n",
        "plt.draw()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJLDlaHUGSdy",
        "colab_type": "text"
      },
      "source": [
        "### Beware of Overfitting\n",
        "\n",
        "* The algorithm is clearly learning to generate the correct hidden state.\n",
        "* Baum Welch does, however, overfit quickly.\n",
        "* It is important to:\n",
        "    * Train on multiple sequences.\n",
        "    * Regularize training.\n",
        "    * Repeat inference with multiple random initial parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JznNmDT8GSdz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = (1-model.state_summary[-2]) > 0.5\n",
        "print(\"Accuracy: \", np.mean(pred == states))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8FkZInlGSd0",
        "colab_type": "text"
      },
      "source": [
        "## Visualize the Computation Graph with Tensorboard\n",
        "\n",
        "Each nodes expends into an exploded view of the computation graph generated by Tensorflow.\n",
        "Check it out!\n",
        "\n",
        "**Run Tensorboard on command line :**\n",
        "\n",
        "> tensorboard --logdir= [graph/file/location](https://github.com/MarvinBertin/HiddenMarkovModel_TensorFlow/tree/master/TensorBoard/Baum-Welch)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6-FvFAlGSd1",
        "colab_type": "text"
      },
      "source": [
        "![](https://github.com/apester/HiddenMarkovModel_TensorFlow/blob/master/images/BW1.png?raw=1)"
      ]
    }
  ]
}